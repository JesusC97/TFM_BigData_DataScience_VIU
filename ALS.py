# -*- coding: utf-8 -*-
"""ALS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eRKp4_sUQNPIycLdY7n643xHy7Gm19iJ
"""

!pip install implicit scikit-learn pandas openpyxl

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse import csr_matrix
import scipy.sparse as sparse
import os
import openpyxl
import implicit
from google.colab import files
from implicit.als import AlternatingLeastSquares

print("Por favor, sube los archivos: Excel con freelancers, texto del cliente y stopwords.")
uploaded = files.upload()

# Cargar el archivo Excel
excel_filename = [f for f in uploaded.keys() if f.endswith('.xlsx')][0]
df_freelancers = pd.read_excel(excel_filename, engine='openpyxl')

# Cargar archivo de texto con la respuesta del cliente
txt_filename = [f for f in uploaded.keys() if f.endswith('.txt') and "RespuestaCliente" in f][0]
with open(txt_filename, "r", encoding="utf-8") as file:
    lines = file.readlines()

# Cargar archivo de stopwords
stopwords_filename = [f for f in uploaded.keys() if f.endswith('.txt') and "stopwords" in f][0]
with open(stopwords_filename, "r", encoding="utf-8") as file:
    stopwords_list = file.read().split(', ')

# Verificar la carga de datos
print("Archivos cargados correctamente.")
print(df_freelancers.head())
print("Primera línea del archivo de texto:", lines[0])
print("Ejemplo de stopwords:", stopwords_list[:10])

# Renombrar columnas para consistencia
df_freelancers.rename(columns={'PreferedName': 'Freelancer',
                               'RespuestaFormulario': 'Formulario',
                               'Skills': 'Habilidades'}, inplace=True)

df_freelancers.dropna(subset=['Habilidades'], inplace=True)

print(df_freelancers['Formulario'].head())

# Convertir respuestas del formulario a listas numéricas
df_freelancers['Formulario'] = df_freelancers['Formulario'].apply(
    lambda x: np.array(list(map(int, x.split(',')))))

print(df_freelancers['Formulario'].head())

print(df_freelancers['Habilidades'].head())

# Convertir habilidades en listas de palabras clave
df_freelancers['Habilidades'] = df_freelancers['Habilidades'].apply(
    lambda x: x.lower().split(', ') if isinstance(x, str) else [])

print(df_freelancers['Habilidades'].head())

# Extraer respuestas del formulario del cliente (primera línea)
cliente_formulario = np.array(list(map(int, lines[0].strip().split(','))))

# Extraer texto del cliente (resto del archivo)
cliente_texto = " ".join(lines[1:]).strip()

print("Formulario del cliente:", cliente_formulario)
print("Texto del cliente:", cliente_texto)

# Convertir el texto del cliente a un string (por si acaso es una lista)
if isinstance(cliente_texto, list):
    cliente_texto = ' '.join(cliente_texto)  # Unir la lista en un solo string

# Limpiar cliente_texto de stopwords
cliente_texto_clean = ' '.join([word for word in cliente_texto.split() if word.lower() not in stopwords_list])

# Vectorizar habilidades con TF
vectorizer = TfidfVectorizer(use_idf=False, norm=None)
tf_matrix = vectorizer.fit_transform([cliente_texto_clean] + df_freelancers['Habilidades'].astype(str).tolist())

# Extraer solo los TF de los freelancers
tf_freelancers = tf_matrix[1:].toarray().sum(axis=1)

# Convertir la columna 'Formulario' en una matriz numpy donde cada fila corresponde a un freelancer
respuestas_freelancers = np.vstack(df_freelancers['Formulario'].values)

# Calcular el puntaje de compatibilidad como la media de las 25 respuestas ajustadas
puntaje_compatibilidad = np.mean(5 - np.abs(respuestas_freelancers - cliente_formulario), axis=1)

# Convertirlo en una matriz dispersa (178 freelancers, 1 cliente)
interactions_item_user = csr_matrix(puntaje_compatibilidad.reshape(-1, 1))

print(respuestas_freelancers)
print(puntaje_compatibilidad)
print(interactions_item_user.shape)

# Normalizar TF entre 0 y 1
scaler = MinMaxScaler()
tf_freelancers_norm = scaler.fit_transform(tf_freelancers.reshape(-1, 1)).flatten()

# Multiplicar matriz de interacciones por la puntuación TF normalizada
interactions_item_user_ponderada = interactions_item_user.multiply(tf_freelancers_norm[:, np.newaxis])


print(interactions_item_user_ponderada)

# Convertimos la matriz a formato disperso para ALS
interactions_item_user_pond = csr_matrix(interactions_item_user_ponderada)

# Definir modelo ALS con hiperparámetros ajustables
model = AlternatingLeastSquares(
    factors=50,          # Número de factores latentes
    regularization=0.1,  # Regularización
    iterations=20,       # Iteraciones
    use_gpu=False        # Configurar en True si hay GPU disponible
)

# ALS espera la transpuesta de la matriz de interacciones
model.fit(interactions_item_user_pond)

interactions_user_item_pond = csr_matrix(interactions_item_user_pond.T)
print("Shape de interactions_user_item_pond:", interactions_user_item_pond.shape)

def recomendar_freelancers_als(model, user_items, cliente_idx=0, top_n=3):
    indices, scores = model.recommend(
        userid=cliente_idx,
        user_items=interactions_user_item_pond,
        N=top_n,
        recalculate_user=False,
        filter_already_liked_items=False  # Desactivar filtrado para evitar error
    )
    print("Scores:", scores)
    print("Índices recomendados:", indices)
    return scores, indices

# Obtener los 3 mejores freelancers usando la matriz user-item
recomendaciones_als = recomendar_freelancers_als(model, interactions_user_item_pond, top_n=3)

print("Freelancers recomendados (ALS):", recomendaciones_als)