# -*- coding: utf-8 -*-
"""LightFM_Prueba.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c5jaeiyy-8OE-rpMBnO1J-txSyvRquid
"""

!pip install lightfm scikit-learn pandas openpyxl

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse import csr_matrix
import os
import re
from google.colab import files
from lightfm import LightFM

print("Por favor, sube los archivos: Excel con freelancers, texto del cliente y stopwords.")
uploaded = files.upload()

# Cargar el archivo Excel
excel_filename = [f for f in uploaded.keys() if f.endswith('.xlsx')][0]
df_freelancers = pd.read_excel(excel_filename, engine='openpyxl')

# Cargar archivo de texto con la respuesta del cliente
txt_filename = [f for f in uploaded.keys() if f.endswith('.txt') and "RespuestaCliente" in f][0]
with open(txt_filename, "r", encoding="utf-8") as file:
    lines = file.readlines()

# Cargar archivo de stopwords
stopwords_filename = [f for f in uploaded.keys() if f.endswith('.txt') and "stopwords" in f][0]
with open(stopwords_filename, "r", encoding="utf-8") as file:
    stopwords_list = file.read().split(', ')

# Verificar la carga de datos
print("Archivos cargados correctamente.")
print(df_freelancers.head())
print("Primera línea del archivo de texto:", lines[0])
print("Ejemplo de stopwords:", stopwords_list[:10])

# Renombrar columnas para consistencia
df_freelancers.rename(columns={'PreferedName': 'Freelancer',
                               'RespuestaFormulario': 'Formulario',
                               'Skills': 'Habilidades'}, inplace=True)

df_freelancers.dropna(subset=['Habilidades'], inplace=True)

print(df_freelancers['Formulario'].head())

# Convertir respuestas del formulario a listas numéricas
df_freelancers['Formulario'] = df_freelancers['Formulario'].apply(
    lambda x: np.array(list(map(int, x.split(',')))))

print(df_freelancers['Formulario'].head())

print(df_freelancers['Habilidades'].head())

# Convertir habilidades en listas de palabras clave
df_freelancers['Habilidades'] = df_freelancers['Habilidades'].apply(
    lambda x: x.lower().split(', ') if isinstance(x, str) else [])

print(df_freelancers['Habilidades'].head())

# Extraer respuestas del formulario del cliente (primera línea)
cliente_formulario = np.array(list(map(int, lines[0].strip().split(','))))

# Extraer texto del cliente (resto del archivo)
cliente_texto = " ".join(lines[1:]).strip()

print("Formulario del cliente:", cliente_formulario)
print("Texto del cliente:", cliente_texto)

# Convertimos a matriz NumPy
respuestas_freelancers = np.array(df_freelancers['Formulario'].tolist())

# Comparamos cada respuesta con la del cliente
matriz_interacciones = (respuestas_freelancers == cliente_formulario).astype(int)

print(matriz_interacciones)

# Convertir el texto del cliente a un string (por si acaso es una lista)
if isinstance(cliente_texto, list):
    cliente_texto = ' '.join(cliente_texto)  # Unir la lista en un solo string

# Limpiar cliente_texto de stopwords
cliente_texto_clean = ' '.join([word for word in cliente_texto.split() if word.lower() not in stopwords_list])

# Vectorizar habilidades con TF
vectorizer = TfidfVectorizer(use_idf=False, norm=None)
tf_matrix = vectorizer.fit_transform([cliente_texto_clean] + df_freelancers['Habilidades'].astype(str).tolist())

# Extraer solo los TF de los freelancers
tf_freelancers = tf_matrix[1:].toarray().sum(axis=1)

# Normalizar TF entre 0 y 1
scaler = MinMaxScaler()
tf_freelancers_norm = scaler.fit_transform(tf_freelancers.reshape(-1, 1)).flatten()

# Multiplicar matriz de interacciones por la puntuación TF normalizada
matriz_interacciones_ponderada = matriz_interacciones * tf_freelancers_norm[:, np.newaxis]

# Convertimos la matriz a formato disperso para LightFM
interactions_sparse = csr_matrix(matriz_interacciones_ponderada)

model = LightFM(loss='warp',no_components=interactions_sparse.shape[1])  # WARP para recomendaciones implícitas
model.fit(interactions_sparse, epochs=30, num_threads=4)

print("Shape de la matriz de interacciones (freelancers x preguntas):", interactions_sparse.shape)
print("Shape de item_features:", interactions_sparse.shape)

def recomendar_freelancers(model, interactions, top_n=3):
    """Genera recomendaciones de freelancers."""
    n_freelancers = interactions_sparse.shape[0]

    # Predecir scores para todos los freelancers
    scores = model.predict(0, np.arange(interactions_sparse.shape[1]))


    # Ordenar de mayor a menor y devolver los top_n
    freelancers_recomendados = np.argsort(-scores)[:top_n]

    return freelancers_recomendados

# Obtener los 3 mejores freelancers
recomendaciones = recomendar_freelancers(model, interactions_sparse, top_n=3)

# Mostrar resultados
print("Freelancers recomendados:", recomendaciones)

# Contar cuántos valores 1 tiene cada freelancer
conteo_relevancia = (matriz_interacciones == 1).sum(axis=1)

# Filtrar freelancers con al menos 10 coincidencias
freelancers_relevantes_idx = np.where(conteo_relevancia >= 5)[0]

# Filtrar la matriz de interacciones y características
matriz_interacciones_filtrada = matriz_interacciones[freelancers_relevantes_idx]

print(matriz_interacciones_filtrada.shape[0])
print(freelancers_relevantes_idx)

# Comprobar si los IDs de los freelancers están en la lista de relevantes
freelancers_encontrados = [fid for fid in recomendaciones if fid in freelancers_relevantes_idx]

print("Num de freelancers que están en la matriz filtrada:", len(freelancers_encontrados))

usuarios_totales=interactions_sparse.shape[0]
usuarios_recomendados=len(recomendaciones)
usuarios_relevantes=matriz_interacciones_filtrada.shape[0]
usuarios_recomendados_relevantes=len(freelancers_encontrados)

print(f"Usuarios totales: {usuarios_totales}")
print(f"Usuarios recomendados: {usuarios_recomendados}")
print(f"Usuarios relevantes: {usuarios_relevantes}")
print(f"Usuarios recomendados relevantes: {usuarios_recomendados_relevantes}")

# Verificar si los denominadores son cero antes de calcular las métricas
if usuarios_totales == 0:
    coverage = 0.0  # Si no hay usuarios totales, el coverage es 0
else:
    coverage = (usuarios_recomendados / usuarios_totales) * 100

if usuarios_recomendados == 0:
    precision = 0.0  # Si no hay usuarios recomendados, la precisión es 0
else:
    precision = (usuarios_recomendados_relevantes / usuarios_recomendados) * 100

if usuarios_relevantes == 0:
    recall = 0.0  # Si no hay usuarios relevantes, el recall es 0
else:
    recall = (usuarios_recomendados_relevantes / usuarios_relevantes)

# Calcular F1-score solo si precision y recall no son ambos cero
if precision + recall == 0:
    f1_score = 0.0  # Si ambos son cero, el F1-score es 0
else:
    f1_score = 2 * ((precision * recall) / (precision + recall))

print(f"Coverage: {coverage:.4f}%")
print(f"Precision: {precision:.4f}%")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1_score:.4f}")